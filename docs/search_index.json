[["text-mining-patent-data.html", "Chapter 16 Text mining Patent data 16.1 Introduction", " Chapter 16 Text mining Patent data 16.1 Introduction In this chapter we will analyse patent data and will process the text contained in patents following a tidytextmining approach, as proposed by @JuliaSilge. This time we have carried a patent search in Lens on sustainable materials for building construction; specifically on Cross Laminated Timber (CLT). We looked for patents in The Lens database using a simple search (timber OR wood) AND (lamina* OR layer*). We downloaded this data as a CSV file into our local directory and will now read it and try to process all the text contained in these patents. First, lets read our data library(tidyverse) CLT &lt;- read_csv(&quot;data/CLT_Lens-export.csv&quot;) We have 1000 patents claiming new inventions involving laminated timber. The data, as exported form Lens, includes bibliographic information but only titles as texts fields (we no dot have abstract information). Therefore we will process the text contained in the patents title. The first thing we need to do is loading all packages that are required for text processing. library(tm) library(tidytext) library(topicmodels) library(widyr) Then we have to select the column field where the textual data we want to process is (in our case we will take the Title field column) clt_text &lt;- CLT$Title head(clt_text) FALSE [1] &quot;Timber Flooring Element Made Of Polymer Bound Wood Strips E.g. For Timber Flooring, Has Several Wooden Strips And Located On Polymer Laminar Layer With Strips Laterally Arranged Distance From Each Other And Connected By Joints&quot; FALSE [2] &quot;Method And System For Timber-conversion Of Lamina For Laminated Timber&quot; FALSE [3] &quot;Light And High-strength Wood Or Bamboo Base Laminar Composite Precast Slab&quot; FALSE [4] &quot;Apparatus For Slicing Wood Laminae From Squared Timber.&quot; FALSE [5] &quot;Apparatus For Slicing Wood Laminae From Squared Timber&quot; FALSE [6] &quot;A Method For Predicting Yield Of Laminar For Cross Laminated Timber&quot; Now we have to build our text corpus from all text contained in the Titles. We will use the Corpus funcion from the tm package. corpustext &lt;- Corpus(VectorSource(clt_text)) Then, we will transform our corpus into a document-term matrix (dtm). The Document-term matrix is a matrix that represents the frequency of occurrence of each term in each patent. We can then extract the terms from this matrix and list them into a tidy format, using the tidy function. dtm &lt;- DocumentTermMatrix(corpustext) clt_text_clean &lt;- tidy(dtm) #View(net) #to see the resulting table We can now order the terms to see the most frequent ones first. clt_text_clean %&gt;% count(term, sort = TRUE) FALSE # A tibble: 2,186 x 2 FALSE term n FALSE &lt;chr&gt; &lt;int&gt; FALSE 1 for 344 FALSE 2 and 277 FALSE 3 wood 205 FALSE 4 method 191 FALSE 5 laminar 111 FALSE 6 the 104 FALSE 7 (machine-translation 103 FALSE 8 binding) 103 FALSE 9 google 103 FALSE 10 legally 103 FALSE # ... with 2,176 more rows We can see that we have many non relevant words (stopwords) in our terms data. We can remove those by creating first a list of stopwords we do not want and then filtering out this list from our data using anti_join. mystopwords &lt;- tibble(term = c(as.character(1:10), &quot;the&quot;, &quot;and&quot;, &quot;for&quot;, &quot;this&quot;, &quot;between&quot;, &quot;than&quot;, &quot;through&quot;, &quot;but&quot;, &quot;have&quot;, &quot;been&quot;, &quot;these&quot;, &quot;that&quot;, &quot;are&quot;, &quot;from&quot;, &quot;with&quot;, &quot;their&quot;, &quot;such&quot;, &quot;also&quot;, &quot;then&quot;, &quot;was&quot;, &quot;were&quot;, &quot;which&quot;, &quot;has&quot;, &quot;its&quot;, &quot;this&quot;, &quot;can&quot;, &quot;paper&quot;, &quot;study&quot;, &quot;presents&quot;, &quot;while&quot;, &quot;[en]&quot;, &quot;first&quot;, &quot;second&quot;, &quot;invention&quot;, &quot;present&quot;, &quot;wherein&quot;, &quot;into&quot;, &quot;discloses&quot;, &quot;being&quot;, &quot;model&quot;, &quot;utility&quot;, &quot;more&quot;, &quot;provide&quot;, &quot;provides&quot;, &quot;plurality&quot;, &quot;each&quot;, &quot;when&quot;, &quot;one&quot;, &quot;provided&quot;, &quot;comprises&quot;, &quot;having&quot;, &quot;least&quot;, &quot;other&quot;, &quot;components&quot;, &quot;retales&quot;, &quot;includes&quot;, &quot;des&quot;, &quot;dans&quot;, &quot;les&quot;, &quot;l.)&quot;, &quot;abstract&quot;, &quot;results&quot;, &quot;found&quot;, &quot;will&quot;, &quot;considered&quot;, &quot;showed&quot;,&quot;only&quot;, &quot;various&quot;, &quot;used&quot;, &quot;waste.&quot;, &quot;waste,&quot;, &quot;proposed&quot;, &quot;carried&quot;, &quot;out&quot;, &quot;using&quot;, &quot;two&quot;, &quot;order&quot;, &quot;both&quot; ,&quot;not&quot; ,&quot;well&quot;, &quot;however&quot;, &quot;due&quot;, &quot;most&quot;, &quot;main&quot;, &quot;all&quot;, &quot;based&quot;, &quot;compared&quot;, &quot;thereof&quot;, &quot;legally&quot;, &quot;binding)&quot;, &quot;said&quot;, &quot;google&quot;, &quot;translate,&quot;, &quot;translate&quot;, &quot;googler&quot;,&quot;methods&quot;, &quot;method&quot;, &quot;(machine-translation&quot;, &quot;same&quot;)) clt_text_clean_no_stopwords &lt;- clt_text_clean %&gt;% anti_join(mystopwords) clt_text_clean_no_stopwords FALSE # A tibble: 5,868 x 3 FALSE document term count FALSE &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; FALSE 1 1 arranged 1 FALSE 2 1 bound 1 FALSE 3 1 connected 1 FALSE 4 1 distance 1 FALSE 5 1 e.g. 1 FALSE 6 1 element 1 FALSE 7 1 flooring 1 FALSE 8 1 flooring, 1 FALSE 9 1 joints 1 FALSE 10 1 laminar 1 FALSE # ... with 5,858 more rows Now we can reorder again terms by frequency clt_text_clean_no_stopwords %&gt;% count(term, sort = TRUE) FALSE # A tibble: 2,133 x 2 FALSE term n FALSE &lt;chr&gt; &lt;int&gt; FALSE 1 wood 205 FALSE 2 laminar 111 FALSE 3 manufacturing 90 FALSE 4 laminated 84 FALSE 5 improvements 81 FALSE 6 material 78 FALSE 7 relating 56 FALSE 8 panel 47 FALSE 9 structure 43 FALSE 10 wooden 43 FALSE # ... with 2,123 more rows To represent term co-ocurrencies (that is, terms jointly appearing in a patent) we need to create first a table containing pairs of terms and their frequency of co-ocurrency. We do that by using the pairwise_count funcion form the widyr package. clt_text_pairs &lt;- clt_text_clean_no_stopwords %&gt;% pairwise_count(term, document, sort = TRUE, upper = FALSE) View(clt_text_pairs) #with pairwise_count we simply count coocurrencies. With pairwise_cor we could compute correlation. See that the created table contains three columns: column item1, column item2 and column n (freq of jointly occurrence of these two terms in a patent). Finally we can visualise top term co-ocurrencies on all of our patents on laminated timber, through a network graph generated with the graph packages igraph and ggraph, together with the visualization library ggplot. library(igraph) library(ggplot2) library(ggraph) set.seed(1234) clt_text_pairs %&gt;% filter(n &gt;= 7) %&gt;% #we filter top most frequent terms graph_from_data_frame() %&gt;% ggraph(layout = &quot;fr&quot;) + geom_edge_link(aes(edge_alpha = n, edge_width = n), edge_colour = &quot;#65BB59&quot;) + geom_node_point(size = 1) + geom_node_text(aes(label = name), repel = TRUE, point.padding = unit(0.2, &quot;lines&quot;)) + labs(title = &quot;word co-ocurrency network&quot;) + theme_void() We see that some titles in patents are obviously in other languages apart form English, such as German, Spanish or Danish "]]
